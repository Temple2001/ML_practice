{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression_practice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+0wo0+uxMrdSeVQb9yBVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Temple2001/ML_practice/blob/main/codes/LinearRegression_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k0J6IaYAHWk"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def numerical_derivative(f, x):\r\n",
        "  delta_x = 1e-4\r\n",
        "  grad = np.zeros_like(x)\r\n",
        "\r\n",
        "  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\r\n",
        "\r\n",
        "  while not it.finished:\r\n",
        "    idx = it.multi_index\r\n",
        "    tmp_val = x[idx]\r\n",
        "    x[idx] = float(tmp_val) + delta_x\r\n",
        "    fx1 = f(x)\r\n",
        "\r\n",
        "    x[idx] = float(tmp_val) - delta_x\r\n",
        "    fx2 = f(x)\r\n",
        "    grad[idx] = (fx1 - fx2) / (2*delta_x)\r\n",
        "\r\n",
        "    x[idx] = tmp_val\r\n",
        "    it.iternext()\r\n",
        "\r\n",
        "  return grad"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDrkXTTJEMXu",
        "outputId": "4982dd77-b95c-42b1-a569-582c5dafd913"
      },
      "source": [
        "x_data = np.array([1.0, 2.0, 3.0, 4.0, 5.0]).reshape(5,1)\r\n",
        "t_data = np.array([2.0, 3.0, 4.0, 5.0, 6.0]).reshape(5,1)\r\n",
        "\r\n",
        "print('x_data.shape = ', x_data.shape, ', t_data.shape = ', t_data.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_data.shape =  (5, 1) , t_data.shape =  (5, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8InSoFuE4xm",
        "outputId": "d29c8d7d-2066-4acd-9a23-1ff9f2259cec"
      },
      "source": [
        "W = np.random.rand(1,1)\r\n",
        "b = np.random.rand(1)\r\n",
        "\r\n",
        "print('W = ', W, ', W.shape = ', W.shape, ', b = ', b, ', b.shape = ', b.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W =  [[0.89190612]] , W.shape =  (1, 1) , b =  [0.76707526] , b.shape =  (1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mXAyRG-Fc7H"
      },
      "source": [
        "def loss_func(x, t):\r\n",
        "  y = np.dot(x,W) + b\r\n",
        "\r\n",
        "  return ( np.sum((t-y)**2) / (len(x)))\r\n",
        "\r\n",
        "def loss_val(x, t):\r\n",
        "  y = np.dot(x,W) + b\r\n",
        "\r\n",
        "  return ( np.sum((t-y)**2) / (len(x)))\r\n",
        "\r\n",
        "def predict(x):\r\n",
        "  y = np.dot(x,W) + b\r\n",
        "  return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXN-rJztF72W"
      },
      "source": [
        "learning_rate = 1e-2\r\n",
        "\r\n",
        "f = lambda x : loss_func(x_data, t_data)\r\n",
        "\r\n",
        "print('initial loss value = ', loss_val(x_data, t_data), 'initial W = ', W, '\\n', ', b = ', b)\r\n",
        "\r\n",
        "for step in range(8001):\r\n",
        "  W -= learning_rate * numerical_derivative(f, W)\r\n",
        "  b -= learning_rate * numerical_derivative(f, b)\r\n",
        "\r\n",
        "  if (step % 400 == 0):\r\n",
        "    print('step = ', step, ', loss value = ', loss_val(x_data, t_data), ', W = ', W, ', b = ', b)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}