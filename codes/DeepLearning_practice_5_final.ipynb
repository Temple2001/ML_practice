{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_practice_5_final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2Uo4uIEoha6ry05HPd0ay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Temple2001/ML_practice/blob/main/codes/DeepLearning_practice_5_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thuGGe_ptZbu"
      },
      "source": [
        "# DataGeneration class 를 이용한 Diabetes 구현\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsLTXiA9dCtN"
      },
      "source": [
        "import numpy as np\r\n",
        "from datetime import datetime\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def numerical_derivative(f, x):\r\n",
        "    delta_x = 1e-4 # 0.0001\r\n",
        "    grad = np.zeros_like(x)\r\n",
        "    \r\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\r\n",
        "    \r\n",
        "    while not it.finished:\r\n",
        "        idx = it.multi_index        \r\n",
        "        tmp_val = x[idx]\r\n",
        "        x[idx] = float(tmp_val) + delta_x\r\n",
        "        fx1 = f(x) # f(x+delta_x)\r\n",
        "        \r\n",
        "        x[idx] = float(tmp_val) - delta_x \r\n",
        "        fx2 = f(x) # f(x-delta_x)\r\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\r\n",
        "        \r\n",
        "        x[idx] = tmp_val \r\n",
        "        it.iternext()   \r\n",
        "        \r\n",
        "    return grad\r\n",
        "\r\n",
        "\r\n",
        "def sigmoid(x):\r\n",
        "    return 1 / (1+np.exp(-x))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W19z1oJBt1cd"
      },
      "source": [
        "class Diabetes:\r\n",
        "\r\n",
        "    def __init__(self, name, input_nodes, hidden1_nodes, output_nodes, learning_rate):\r\n",
        "        self.name = name\r\n",
        "        \r\n",
        "        self.W2 = np.random.rand(input_nodes, hidden1_nodes)\r\n",
        "        self.b2 = np.random.rand(hidden1_nodes)\r\n",
        "\r\n",
        "        self.W3 = np.random.rand(hidden1_nodes, output_nodes)\r\n",
        "        self.b3 = np.random.rand(output_nodes)\r\n",
        "\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "\r\n",
        "        print(self.name, ' is created !!!')\r\n",
        "    \r\n",
        "    def feed_forward(self):\r\n",
        "        delta = 1e-7\r\n",
        "\r\n",
        "        z2 = np.dot(self.input_data, self.W2) + self.b2\r\n",
        "        a2 = sigmoid(z2)\r\n",
        "\r\n",
        "        z3 = np.dot(a2, self.W3) + self.b3\r\n",
        "        y = a3 = sigmoid(z3)\r\n",
        "\r\n",
        "        return -np.sum(self.target_data*np.log(y+delta)+(1-self.target_data)*np.log((1-y)+delta))\r\n",
        "    \r\n",
        "    def loss_val(self):\r\n",
        "        delta = 1e-7\r\n",
        "\r\n",
        "        z2 = np.dot(self.input_data, self.W2) + self.b2\r\n",
        "        a2 = sigmoid(z2)\r\n",
        "\r\n",
        "        z3 = np.dot(a2, self.W3) + self.b3\r\n",
        "        y = a3 = sigmoid(z3)\r\n",
        "\r\n",
        "        return -np.sum(self.target_data*np.log(y+delta)+(1-self.target_data)*np.log((1-y)+delta))\r\n",
        "\r\n",
        "    def predict(self, input_data):\r\n",
        "        z2 = np.dot(self.input_data, self.W2) + self.b2\r\n",
        "        a2 = sigmoid(z2)\r\n",
        "\r\n",
        "        z3 = np.dot(a2, self.W3) + self.b3\r\n",
        "        y = a3 = sigmoid(z3)\r\n",
        "\r\n",
        "        if y >= 0.5:\r\n",
        "            result = 1\r\n",
        "        else:\r\n",
        "            result = 0\r\n",
        "        \r\n",
        "        return y, result\r\n",
        "    \r\n",
        "    def accuracy(self, input_data, target_data):\r\n",
        "        matched_list = []\r\n",
        "        not_matched_list = []\r\n",
        "\r\n",
        "        for index in range(len(input_data)):\r\n",
        "            (real_val, logical_val) = self.predict(input_data[index])\r\n",
        "\r\n",
        "            if logical_val == target_data[index]:\r\n",
        "                matched_list.append(index)\r\n",
        "            else:\r\n",
        "                not_matched_list.append(index)\r\n",
        "        \r\n",
        "        accuracy_val = len(matched_list) / len(input_data)\r\n",
        "\r\n",
        "        return accuracy_val\r\n",
        "    \r\n",
        "    def train(self, input_data, target_data):\r\n",
        "        self.input_data = input_data\r\n",
        "        self.target_data = target_data\r\n",
        "\r\n",
        "        f = lambda x : self.feed_forward()\r\n",
        "\r\n",
        "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\r\n",
        "    \r\n",
        "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\r\n",
        "        \r\n",
        "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\r\n",
        "    \r\n",
        "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54tlQ4dHyNUx"
      },
      "source": [
        "class DataGeneration:\r\n",
        "\r\n",
        "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\r\n",
        "        self.name = name\r\n",
        "        self.file_path = file_path\r\n",
        "        self.seperation_rate = seperation_rate\r\n",
        "\r\n",
        "        if (target_position == -1 or target_position == 0):\r\n",
        "            self.target_position = target_position\r\n",
        "        else:\r\n",
        "            err_str = 'target_position must be -1 or 0'\r\n",
        "            raise Exception(err_str)\r\n",
        "    \r\n",
        "    def __display_target_distribution(self, data, str_of_kind='original data'):\r\n",
        "        print('=========================================================================================')\r\n",
        "\r\n",
        "        target_data = data[:, self.target_position]\r\n",
        "\r\n",
        "        unique, counts = np.unique(target_data, return_counts='True')\r\n",
        "\r\n",
        "        unique_target = []\r\n",
        "\r\n",
        "        for index in range(len(unique)):\r\n",
        "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\r\n",
        "            unique_target.append(unique[index])\r\n",
        "        \r\n",
        "        for index in range(len(unique_target)):\r\n",
        "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100*counts[index] / (target_data.shape[0]), 2), ' %')\r\n",
        "\r\n",
        "        print('=========================================================================================')\r\n",
        "    \r\n",
        "    def generate(self):\r\n",
        "        try:\r\n",
        "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\r\n",
        "        except Exception as err:\r\n",
        "            print('[DataGeneration::generate()]  ', str(err))\r\n",
        "            raise Exception(str(err))\r\n",
        "        \r\n",
        "        print('[DataGeneration] loaded_data.shape = ', loaded_data.shape)\r\n",
        "\r\n",
        "        self.__display_target_distribution(loaded_data, 'original data')\r\n",
        "\r\n",
        "        total_data_num = len(loaded_data)\r\n",
        "        test_data_num = int(len(loaded_data)*self.seperation_rate)\r\n",
        "\r\n",
        "        np.random.shuffle(loaded_data)\r\n",
        "\r\n",
        "        test_data = loaded_data[0:test_data_num]\r\n",
        "\r\n",
        "        training_data = loaded_data[test_data_num:]\r\n",
        "\r\n",
        "        self.__display_target_distribution(training_data, 'training data')\r\n",
        "        self.__display_target_distribution(test_data, 'test data')\r\n",
        "\r\n",
        "        return training_data, test_data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgcFEyG91vV5",
        "outputId": "e689ae05-fcd5-41f6-8338-9f2c11e6666b"
      },
      "source": [
        "test_seperation_rate = 0.4\r\n",
        "\r\n",
        "try:\r\n",
        "    data_obj = DataGeneration('Diabetes', 'diabetes.csv', test_seperation_rate)\r\n",
        "    (training_data, test_data) = data_obj.generate()\r\n",
        "\r\n",
        "    print('================================================')\r\n",
        "    print('training data.shape = ', training_data.shape)\r\n",
        "    print('test data.shape = ', test_data.shape)\r\n",
        "    print('================================================')\r\n",
        "    \r\n",
        "except Exception as err:\r\n",
        "    print('Exception occur !!')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DataGeneration] loaded_data.shape =  (759, 9)\n",
            "=========================================================================================\n",
            "[DataGeneration] unique number of original data =  0.0 , count =  263\n",
            "[DataGeneration] unique number of original data =  1.0 , count =  496\n",
            "[DataGeneration] unique number of original data =  0.0 , ratio =  34.65  %\n",
            "[DataGeneration] unique number of original data =  1.0 , ratio =  65.35  %\n",
            "=========================================================================================\n",
            "=========================================================================================\n",
            "[DataGeneration] unique number of training data =  0.0 , count =  154\n",
            "[DataGeneration] unique number of training data =  1.0 , count =  302\n",
            "[DataGeneration] unique number of training data =  0.0 , ratio =  33.77  %\n",
            "[DataGeneration] unique number of training data =  1.0 , ratio =  66.23  %\n",
            "=========================================================================================\n",
            "=========================================================================================\n",
            "[DataGeneration] unique number of test data =  0.0 , count =  109\n",
            "[DataGeneration] unique number of test data =  1.0 , count =  194\n",
            "[DataGeneration] unique number of test data =  0.0 , ratio =  35.97  %\n",
            "[DataGeneration] unique number of test data =  1.0 , ratio =  64.03  %\n",
            "=========================================================================================\n",
            "================================================\n",
            "training data.shape =  (456, 9)\n",
            "test data.shape =  (303, 9)\n",
            "================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7KPD-_-BTcM",
        "outputId": "aa726167-8642-4fb7-e7bb-d08dd36aa1b0"
      },
      "source": [
        "i_nodes = training_data.shape[1] - 1\r\n",
        "h1_nodes = 20\r\n",
        "o_nodes = 1\r\n",
        "lr = 1e-2\r\n",
        "epochs = 20\r\n",
        "\r\n",
        "loss_val_list = []\r\n",
        "accuracy_val_list = []\r\n",
        "validation_accuracy_val_list = []\r\n",
        "\r\n",
        "obj1 = Diabetes('Diabetes', i_nodes, h1_nodes, o_nodes, lr)\r\n",
        "\r\n",
        "print('Neural Network Learning using Numerical Derivative...')\r\n",
        "\r\n",
        "start_time = datetime.now()\r\n",
        "\r\n",
        "for step in range(epochs):\r\n",
        "    for index in range(len(training_data)):\r\n",
        "        input_data = training_data[index, 0:-1]\r\n",
        "        target_data = training_data[index, [-1]]\r\n",
        "\r\n",
        "        obj1.train(input_data, target_data)\r\n",
        "    \r\n",
        "    cur_loss_val = obj1.loss_val()\r\n",
        "    loss_val_list.append(cur_loss_val)\r\n",
        "    training_accuracy = obj1.accuracy(training_data[:,0:-1],training_data[:,-1])\r\n",
        "    validation_accuracy = obj1.accuracy(test_data[:,0:-1], test_data[:,-1])\r\n",
        "\r\n",
        "    print('============================================================================')\r\n",
        "    print('step = ', step, ',                 current loss value = ', cur_loss_val, '\\n')\r\n",
        "    print('step = ', step, ', [training data] accuracy value = ', np.round(100*training_accuracy,4), ' %')\r\n",
        "    \r\n",
        "    accuracy_val_list.append(training_accuracy)\r\n",
        "\r\n",
        "    print('step = ', step, ', [validation data] accuracy valude = ', np.round(100*validation_accuracy, 4), ' %')\r\n",
        "\r\n",
        "    validation_accuracy_val_list.append(validation_accuracy)\r\n",
        "\r\n",
        "print('============================================================================')\r\n",
        "\r\n",
        "end_time = datetime.now()\r\n",
        "\r\n",
        "print('')\r\n",
        "print('Elapsed time => ', end_time - start_time)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diabetes  is created !!!\n",
            "Neural Network Learning using Numerical Derivative...\n",
            "============================================================================\n",
            "step =  0 ,                 current loss value =  0.3026954060074913 \n",
            "\n",
            "step =  0 , [training data] accuracy value =  66.2281  %\n",
            "step =  0 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  1 ,                 current loss value =  0.3793426753459503 \n",
            "\n",
            "step =  1 , [training data] accuracy value =  66.2281  %\n",
            "step =  1 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  2 ,                 current loss value =  0.43005384343228076 \n",
            "\n",
            "step =  2 , [training data] accuracy value =  66.2281  %\n",
            "step =  2 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  3 ,                 current loss value =  0.47796966188699447 \n",
            "\n",
            "step =  3 , [training data] accuracy value =  66.2281  %\n",
            "step =  3 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  4 ,                 current loss value =  0.5234729287275859 \n",
            "\n",
            "step =  4 , [training data] accuracy value =  66.2281  %\n",
            "step =  4 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  5 ,                 current loss value =  0.5667283174942698 \n",
            "\n",
            "step =  5 , [training data] accuracy value =  66.2281  %\n",
            "step =  5 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  6 ,                 current loss value =  0.6078483060774815 \n",
            "\n",
            "step =  6 , [training data] accuracy value =  66.2281  %\n",
            "step =  6 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  7 ,                 current loss value =  0.6469095852288115 \n",
            "\n",
            "step =  7 , [training data] accuracy value =  66.2281  %\n",
            "step =  7 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  8 ,                 current loss value =  0.6839663385851712 \n",
            "\n",
            "step =  8 , [training data] accuracy value =  66.2281  %\n",
            "step =  8 , [validation data] accuracy valude =  64.0264  %\n",
            "============================================================================\n",
            "step =  9 ,                 current loss value =  0.7190596813021799 \n",
            "\n",
            "step =  9 , [training data] accuracy value =  33.7719  %\n",
            "step =  9 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  10 ,                 current loss value =  0.7522238561328669 \n",
            "\n",
            "step =  10 , [training data] accuracy value =  33.7719  %\n",
            "step =  10 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  11 ,                 current loss value =  0.7834902568364666 \n",
            "\n",
            "step =  11 , [training data] accuracy value =  33.7719  %\n",
            "step =  11 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  12 ,                 current loss value =  0.8128901965336444 \n",
            "\n",
            "step =  12 , [training data] accuracy value =  33.7719  %\n",
            "step =  12 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  13 ,                 current loss value =  0.8404570369096557 \n",
            "\n",
            "step =  13 , [training data] accuracy value =  33.7719  %\n",
            "step =  13 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  14 ,                 current loss value =  0.8662280170756254 \n",
            "\n",
            "step =  14 , [training data] accuracy value =  33.7719  %\n",
            "step =  14 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  15 ,                 current loss value =  0.8902459138601969 \n",
            "\n",
            "step =  15 , [training data] accuracy value =  33.7719  %\n",
            "step =  15 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  16 ,                 current loss value =  0.9125605267583807 \n",
            "\n",
            "step =  16 , [training data] accuracy value =  33.7719  %\n",
            "step =  16 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  17 ,                 current loss value =  0.9332298975526049 \n",
            "\n",
            "step =  17 , [training data] accuracy value =  33.7719  %\n",
            "step =  17 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  18 ,                 current loss value =  0.9523211355682182 \n",
            "\n",
            "step =  18 , [training data] accuracy value =  33.7719  %\n",
            "step =  18 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "step =  19 ,                 current loss value =  0.9699107176796417 \n",
            "\n",
            "step =  19 , [training data] accuracy value =  33.7719  %\n",
            "step =  19 , [validation data] accuracy valude =  35.9736  %\n",
            "============================================================================\n",
            "\n",
            "Elapsed time =>  0:01:56.717312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce00uMCyH9Qr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}